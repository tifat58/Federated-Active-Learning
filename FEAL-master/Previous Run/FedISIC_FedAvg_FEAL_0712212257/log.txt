[21:22:57.187] Namespace(fl_method='FedAvg', al_method='FEAL', dataset='FedISIC', max_round=100, al_round=5, query_model='both', query_ratio=0, budget=250, batch_size=4, base_lr=0.0005, deterministic=False, seed=123, display_freq=20, kl_weight=0.01, annealing_step=10, n_neighbor=5, cosine=0.85)
[21:22:57.322] Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
[21:22:57.524] [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[21:22:58.242] Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
[21:22:58.376] [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[21:22:58.424] Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
[21:22:58.545] [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[21:22:58.594] Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
[21:22:58.712] [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[21:22:58.728] 
AL round 1
[21:22:58.761] Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
[21:22:58.882] [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[21:23:17.296] [0.25 0.25 0.25 0.25]
[21:23:32.843] [0.25 0.25 0.25 0.25]
[21:23:48.423] [0.25 0.25 0.25 0.25]
[21:24:04.035] [0.25 0.25 0.25 0.25]
[21:24:19.662] [0.25 0.25 0.25 0.25]
[21:25:01.618] [0.25 0.25 0.25 0.25]
[21:25:17.283] [0.25 0.25 0.25 0.25]
[21:25:32.969] [0.25 0.25 0.25 0.25]
[21:25:48.659] [0.25 0.25 0.25 0.25]
[21:26:04.369] [0.25 0.25 0.25 0.25]
[21:26:46.462] [0.25 0.25 0.25 0.25]
[21:27:02.178] [0.25 0.25 0.25 0.25]
[21:27:17.917] [0.25 0.25 0.25 0.25]
[21:27:33.676] [0.25 0.25 0.25 0.25]
[21:27:49.404] [0.25 0.25 0.25 0.25]
[21:28:31.590] [0.25 0.25 0.25 0.25]
[21:28:47.331] [0.25 0.25 0.25 0.25]
[21:29:03.092] [0.25 0.25 0.25 0.25]
[21:29:18.881] [0.25 0.25 0.25 0.25]
[21:29:34.630] [0.25 0.25 0.25 0.25]
[21:30:16.866] [0.25 0.25 0.25 0.25]
[21:30:32.639] [0.25 0.25 0.25 0.25]
[21:30:48.392] [0.25 0.25 0.25 0.25]
[21:31:04.173] [0.25 0.25 0.25 0.25]
[21:31:19.961] [0.25 0.25 0.25 0.25]
[21:32:02.237] [0.25 0.25 0.25 0.25]
[21:32:18.045] [0.25 0.25 0.25 0.25]
[21:32:33.838] [0.25 0.25 0.25 0.25]
[21:32:49.630] [0.25 0.25 0.25 0.25]
[21:33:05.432] [0.25 0.25 0.25 0.25]
[21:33:47.715] [0.25 0.25 0.25 0.25]
[21:34:03.535] [0.25 0.25 0.25 0.25]
[21:34:19.370] [0.25 0.25 0.25 0.25]
[21:34:35.181] [0.25 0.25 0.25 0.25]
[21:34:50.987] [0.25 0.25 0.25 0.25]
[21:35:33.342] [0.25 0.25 0.25 0.25]
[21:35:49.139] [0.25 0.25 0.25 0.25]
[21:36:04.944] [0.25 0.25 0.25 0.25]
[21:36:20.750] [0.25 0.25 0.25 0.25]
[21:36:36.558] [0.25 0.25 0.25 0.25]
[21:37:18.903] [0.25 0.25 0.25 0.25]
[21:37:34.724] [0.25 0.25 0.25 0.25]
[21:37:50.564] [0.25 0.25 0.25 0.25]
[21:38:06.401] [0.25 0.25 0.25 0.25]
[21:38:22.224] [0.25 0.25 0.25 0.25]
[21:39:04.568] [0.25 0.25 0.25 0.25]
[21:39:20.416] [0.25 0.25 0.25 0.25]
[21:39:36.252] [0.25 0.25 0.25 0.25]
[21:39:52.071] [0.25 0.25 0.25 0.25]
[21:40:07.903] [0.25 0.25 0.25 0.25]
[21:40:50.288] [0.25 0.25 0.25 0.25]
[21:41:06.113] [0.25 0.25 0.25 0.25]
[21:41:21.966] [0.25 0.25 0.25 0.25]
[21:41:37.814] [0.25 0.25 0.25 0.25]
[21:41:53.653] [0.25 0.25 0.25 0.25]
[21:42:36.033] [0.25 0.25 0.25 0.25]
[21:42:51.882] [0.25 0.25 0.25 0.25]
[21:43:07.723] [0.25 0.25 0.25 0.25]
[21:43:23.552] [0.25 0.25 0.25 0.25]
[21:43:39.409] [0.25 0.25 0.25 0.25]
[21:44:21.835] [0.25 0.25 0.25 0.25]
[21:44:37.687] [0.25 0.25 0.25 0.25]
[21:44:53.557] [0.25 0.25 0.25 0.25]
[21:45:09.414] [0.25 0.25 0.25 0.25]
[21:45:25.275] [0.25 0.25 0.25 0.25]
[21:46:07.711] [0.25 0.25 0.25 0.25]
[21:46:23.594] [0.25 0.25 0.25 0.25]
[21:46:39.442] [0.25 0.25 0.25 0.25]
[21:46:55.305] [0.25 0.25 0.25 0.25]
[21:47:11.165] [0.25 0.25 0.25 0.25]
[21:47:53.624] [0.25 0.25 0.25 0.25]
[21:48:09.519] [0.25 0.25 0.25 0.25]
[21:48:25.406] [0.25 0.25 0.25 0.25]
[21:48:41.278] [0.25 0.25 0.25 0.25]
[21:48:57.131] [0.25 0.25 0.25 0.25]
[21:49:39.591] [0.25 0.25 0.25 0.25]
[21:49:55.476] [0.25 0.25 0.25 0.25]
[21:50:11.349] [0.25 0.25 0.25 0.25]
[21:50:27.222] [0.25 0.25 0.25 0.25]
[21:50:43.113] [0.25 0.25 0.25 0.25]
[21:51:25.596] [0.25 0.25 0.25 0.25]
[21:51:41.509] [0.25 0.25 0.25 0.25]
[21:51:57.369] [0.25 0.25 0.25 0.25]
[21:52:13.246] [0.25 0.25 0.25 0.25]
[21:52:29.155] [0.25 0.25 0.25 0.25]
[21:53:11.632] [0.25 0.25 0.25 0.25]
[21:53:27.518] [0.25 0.25 0.25 0.25]
[21:53:43.390] [0.25 0.25 0.25 0.25]
[21:53:59.269] [0.25 0.25 0.25 0.25]
[21:54:15.151] [0.25 0.25 0.25 0.25]
[21:54:57.639] [0.25 0.25 0.25 0.25]
[21:55:13.535] [0.25 0.25 0.25 0.25]
[21:55:29.430] [0.25 0.25 0.25 0.25]
[21:55:45.335] [0.25 0.25 0.25 0.25]
[21:56:01.208] [0.25 0.25 0.25 0.25]
[21:56:43.701] [0.25 0.25 0.25 0.25]
[21:56:59.621] [0.25 0.25 0.25 0.25]
[21:57:15.525] [0.25 0.25 0.25 0.25]
[21:57:31.391] [0.25 0.25 0.25 0.25]
[21:57:47.253] [0.25 0.25 0.25 0.25]
[22:01:21.772] 
AL round 2
[22:01:21.808] Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
[22:01:22.007] [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[22:01:57.212] [0.25 0.25 0.25 0.25]
[22:02:28.170] [0.25 0.25 0.25 0.25]
[22:02:59.144] [0.25 0.25 0.25 0.25]
[22:03:30.119] [0.25 0.25 0.25 0.25]
[22:04:01.092] [0.25 0.25 0.25 0.25]
[22:04:58.745] [0.25 0.25 0.25 0.25]
[22:05:29.720] [0.25 0.25 0.25 0.25]
[22:06:00.695] [0.25 0.25 0.25 0.25]
[22:06:31.665] [0.25 0.25 0.25 0.25]
[22:07:02.679] [0.25 0.25 0.25 0.25]
[22:08:00.291] [0.25 0.25 0.25 0.25]
[22:08:31.269] [0.25 0.25 0.25 0.25]
[22:09:02.241] [0.25 0.25 0.25 0.25]
[22:09:33.216] [0.25 0.25 0.25 0.25]
[22:10:04.188] [0.25 0.25 0.25 0.25]
[22:11:01.806] [0.25 0.25 0.25 0.25]
[22:11:32.781] [0.25 0.25 0.25 0.25]
[22:12:03.791] [0.25 0.25 0.25 0.25]
[22:12:34.762] [0.25 0.25 0.25 0.25]
[22:13:05.733] [0.25 0.25 0.25 0.25]
[22:14:03.307] [0.25 0.25 0.25 0.25]
[22:14:34.289] [0.25 0.25 0.25 0.25]
[22:15:05.263] [0.25 0.25 0.25 0.25]
[22:15:36.275] [0.25 0.25 0.25 0.25]
[22:16:07.254] [0.25 0.25 0.25 0.25]
[22:17:04.860] [0.25 0.25 0.25 0.25]
[22:17:35.871] [0.25 0.25 0.25 0.25]
[22:18:06.850] [0.25 0.25 0.25 0.25]
[22:18:37.820] [0.25 0.25 0.25 0.25]
[22:19:08.801] [0.25 0.25 0.25 0.25]
[22:20:06.409] [0.25 0.25 0.25 0.25]
[22:20:37.380] [0.25 0.25 0.25 0.25]
[22:21:08.356] [0.25 0.25 0.25 0.25]
[22:21:39.335] [0.25 0.25 0.25 0.25]
[22:22:10.347] [0.25 0.25 0.25 0.25]
[22:23:07.956] [0.25 0.25 0.25 0.25]
[22:23:38.935] [0.25 0.25 0.25 0.25]
[22:24:09.948] [0.25 0.25 0.25 0.25]
[22:24:40.917] [0.25 0.25 0.25 0.25]
[22:25:11.897] [0.25 0.25 0.25 0.25]
[22:26:09.504] [0.25 0.25 0.25 0.25]
[22:26:40.486] [0.25 0.25 0.25 0.25]
[22:27:11.448] [0.25 0.25 0.25 0.25]
[22:27:42.433] [0.25 0.25 0.25 0.25]
[22:28:13.443] [0.25 0.25 0.25 0.25]
[22:29:11.055] [0.25 0.25 0.25 0.25]
[22:29:42.071] [0.25 0.25 0.25 0.25]
[22:30:13.044] [0.25 0.25 0.25 0.25]
[22:30:44.018] [0.25 0.25 0.25 0.25]
[22:31:14.999] [0.25 0.25 0.25 0.25]
[22:32:12.606] [0.25 0.25 0.25 0.25]
[22:32:43.580] [0.25 0.25 0.25 0.25]
[22:33:14.554] [0.25 0.25 0.25 0.25]
[22:33:45.534] [0.25 0.25 0.25 0.25]
[22:34:16.502] [0.25 0.25 0.25 0.25]
[22:35:14.116] [0.25 0.25 0.25 0.25]
[22:35:45.090] [0.25 0.25 0.25 0.25]
[22:36:16.063] [0.25 0.25 0.25 0.25]
[22:36:47.039] [0.25 0.25 0.25 0.25]
[22:37:18.011] [0.25 0.25 0.25 0.25]
[22:38:15.584] [0.25 0.25 0.25 0.25]
[22:38:46.558] [0.25 0.25 0.25 0.25]
[22:39:17.533] [0.25 0.25 0.25 0.25]
[22:39:48.509] [0.25 0.25 0.25 0.25]
[22:40:19.475] [0.25 0.25 0.25 0.25]
[22:41:17.093] [0.25 0.25 0.25 0.25]
[22:41:48.070] [0.25 0.25 0.25 0.25]
[22:42:19.045] [0.25 0.25 0.25 0.25]
[22:42:49.979] [0.25 0.25 0.25 0.25]
[22:43:20.946] [0.25 0.25 0.25 0.25]
[22:44:18.566] [0.25 0.25 0.25 0.25]
[22:44:49.538] [0.25 0.25 0.25 0.25]
[22:45:20.492] [0.25 0.25 0.25 0.25]
[22:45:51.451] [0.25 0.25 0.25 0.25]
[22:46:22.424] [0.25 0.25 0.25 0.25]
[22:47:20.041] [0.25 0.25 0.25 0.25]
[22:47:51.012] [0.25 0.25 0.25 0.25]
[22:48:21.988] [0.25 0.25 0.25 0.25]
[22:48:52.945] [0.25 0.25 0.25 0.25]
[22:49:23.935] [0.25 0.25 0.25 0.25]
[22:50:21.506] [0.25 0.25 0.25 0.25]
[22:50:52.481] [0.25 0.25 0.25 0.25]
[22:51:23.447] [0.25 0.25 0.25 0.25]
[22:51:54.446] [0.25 0.25 0.25 0.25]
[22:52:25.437] [0.25 0.25 0.25 0.25]
[22:53:23.013] [0.25 0.25 0.25 0.25]
[22:53:53.984] [0.25 0.25 0.25 0.25]
[22:54:24.959] [0.25 0.25 0.25 0.25]
[22:54:55.940] [0.25 0.25 0.25 0.25]
[22:55:26.907] [0.25 0.25 0.25 0.25]
[22:56:24.490] [0.25 0.25 0.25 0.25]
[22:56:55.462] [0.25 0.25 0.25 0.25]
[22:57:26.434] [0.25 0.25 0.25 0.25]
[22:57:57.368] [0.25 0.25 0.25 0.25]
[22:58:28.345] [0.25 0.25 0.25 0.25]
[22:59:25.910] [0.25 0.25 0.25 0.25]
[22:59:56.858] [0.25 0.25 0.25 0.25]
[23:00:27.828] [0.25 0.25 0.25 0.25]
[23:00:58.808] [0.25 0.25 0.25 0.25]
[23:01:29.761] [0.25 0.25 0.25 0.25]
[23:04:56.390] 
AL round 3
[23:04:56.425] Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
[23:04:56.590] [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[23:05:48.421] [0.25 0.25 0.25 0.25]
[23:06:34.560] [0.25 0.25 0.25 0.25]
[23:07:20.731] [0.25 0.25 0.25 0.25]
[23:08:06.896] [0.25 0.25 0.25 0.25]
[23:08:53.063] [0.25 0.25 0.25 0.25]
[23:10:05.836] [0.25 0.25 0.25 0.25]
[23:10:52.007] [0.25 0.25 0.25 0.25]
[23:11:38.174] [0.25 0.25 0.25 0.25]
[23:12:24.300] [0.25 0.25 0.25 0.25]
[23:13:10.470] [0.25 0.25 0.25 0.25]
[23:14:23.274] [0.25 0.25 0.25 0.25]
[23:15:09.406] [0.25 0.25 0.25 0.25]
[23:15:55.537] [0.25 0.25 0.25 0.25]
[23:16:41.664] [0.25 0.25 0.25 0.25]
[23:17:27.832] [0.25 0.25 0.25 0.25]
[23:18:40.555] [0.25 0.25 0.25 0.25]
[23:19:26.726] [0.25 0.25 0.25 0.25]
[23:20:12.894] [0.25 0.25 0.25 0.25]
[23:20:59.066] [0.25 0.25 0.25 0.25]
[23:21:45.235] [0.25 0.25 0.25 0.25]
[23:22:57.965] [0.25 0.25 0.25 0.25]
[23:23:44.133] [0.25 0.25 0.25 0.25]
[23:24:30.259] [0.25 0.25 0.25 0.25]
[23:25:16.393] [0.25 0.25 0.25 0.25]
[23:26:02.562] [0.25 0.25 0.25 0.25]
[23:27:15.330] [0.25 0.25 0.25 0.25]
[23:28:01.457] [0.25 0.25 0.25 0.25]
[23:28:47.624] [0.25 0.25 0.25 0.25]
[23:29:33.744] [0.25 0.25 0.25 0.25]
[23:30:19.882] [0.25 0.25 0.25 0.25]
[23:31:32.612] [0.25 0.25 0.25 0.25]
[23:32:18.744] [0.25 0.25 0.25 0.25]
[23:33:04.913] [0.25 0.25 0.25 0.25]
[23:33:51.038] [0.25 0.25 0.25 0.25]
[23:34:37.167] [0.25 0.25 0.25 0.25]
[23:35:49.900] [0.25 0.25 0.25 0.25]
[23:36:36.067] [0.25 0.25 0.25 0.25]
[23:37:22.189] [0.25 0.25 0.25 0.25]
[23:38:08.315] [0.25 0.25 0.25 0.25]
[23:38:54.414] [0.25 0.25 0.25 0.25]
[23:40:07.138] [0.25 0.25 0.25 0.25]
[23:40:53.247] [0.25 0.25 0.25 0.25]
[23:41:39.362] [0.25 0.25 0.25 0.25]
[23:42:25.481] [0.25 0.25 0.25 0.25]
[23:43:11.580] [0.25 0.25 0.25 0.25]
[23:44:24.272] [0.25 0.25 0.25 0.25]
[23:45:10.398] [0.25 0.25 0.25 0.25]
[23:45:56.507] [0.25 0.25 0.25 0.25]
[23:46:42.650] [0.25 0.25 0.25 0.25]
[23:47:28.782] [0.25 0.25 0.25 0.25]
[23:48:41.552] [0.25 0.25 0.25 0.25]
[23:49:27.677] [0.25 0.25 0.25 0.25]
[23:50:13.767] [0.25 0.25 0.25 0.25]
[23:50:59.892] [0.25 0.25 0.25 0.25]
[23:51:45.988] [0.25 0.25 0.25 0.25]
[23:52:58.728] [0.25 0.25 0.25 0.25]
[23:53:44.853] [0.25 0.25 0.25 0.25]
[23:54:30.983] [0.25 0.25 0.25 0.25]
[23:55:17.073] [0.25 0.25 0.25 0.25]
[23:56:03.195] [0.25 0.25 0.25 0.25]
[23:57:15.928] [0.25 0.25 0.25 0.25]
[23:58:02.059] [0.25 0.25 0.25 0.25]
[23:58:48.184] [0.25 0.25 0.25 0.25]
[23:59:34.307] [0.25 0.25 0.25 0.25]
[00:00:20.452] [0.25 0.25 0.25 0.25]
[00:01:33.212] [0.25 0.25 0.25 0.25]
[00:02:19.348] [0.25 0.25 0.25 0.25]
[00:03:05.468] [0.25 0.25 0.25 0.25]
[00:03:51.603] [0.25 0.25 0.25 0.25]
[00:04:37.727] [0.25 0.25 0.25 0.25]
[00:05:50.461] [0.25 0.25 0.25 0.25]
[00:06:36.579] [0.25 0.25 0.25 0.25]
[00:07:22.681] [0.25 0.25 0.25 0.25]
[00:08:08.807] [0.25 0.25 0.25 0.25]
[00:08:54.890] [0.25 0.25 0.25 0.25]
[00:10:07.625] [0.25 0.25 0.25 0.25]
[00:10:53.717] [0.25 0.25 0.25 0.25]
[00:11:39.833] [0.25 0.25 0.25 0.25]
[00:12:25.917] [0.25 0.25 0.25 0.25]
[00:13:12.025] [0.25 0.25 0.25 0.25]
[00:14:24.717] [0.25 0.25 0.25 0.25]
[00:15:10.804] [0.25 0.25 0.25 0.25]
[00:15:56.900] [0.25 0.25 0.25 0.25]
[00:16:43.004] [0.25 0.25 0.25 0.25]
[00:17:29.117] [0.25 0.25 0.25 0.25]
[00:18:41.833] [0.25 0.25 0.25 0.25]
[00:19:27.899] [0.25 0.25 0.25 0.25]
[00:20:13.975] [0.25 0.25 0.25 0.25]
[00:21:00.093] [0.25 0.25 0.25 0.25]
[00:21:46.164] [0.25 0.25 0.25 0.25]
[00:22:58.807] [0.25 0.25 0.25 0.25]
[00:23:44.871] [0.25 0.25 0.25 0.25]
[00:24:30.954] [0.25 0.25 0.25 0.25]
[00:25:17.005] [0.25 0.25 0.25 0.25]
[00:26:03.077] [0.25 0.25 0.25 0.25]
[00:27:15.721] [0.25 0.25 0.25 0.25]
[00:28:01.806] [0.25 0.25 0.25 0.25]
[00:28:47.895] [0.25 0.25 0.25 0.25]
[00:29:34.026] [0.25 0.25 0.25 0.25]
[00:30:20.148] [0.25 0.25 0.25 0.25]
[00:33:38.945] 
AL round 4
[00:33:38.979] Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
[00:33:39.379] [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[00:34:47.989] [0.25 0.25 0.25 0.25]
[00:35:49.190] [0.25 0.25 0.25 0.25]
[00:36:50.402] [0.25 0.25 0.25 0.25]
[00:37:51.607] [0.25 0.25 0.25 0.25]
[00:38:52.777] [0.25 0.25 0.25 0.25]
[00:40:20.531] [0.25 0.25 0.25 0.25]
[00:41:21.697] [0.25 0.25 0.25 0.25]
[00:42:22.854] [0.25 0.25 0.25 0.25]
[00:43:24.003] [0.25 0.25 0.25 0.25]
[00:44:25.163] [0.25 0.25 0.25 0.25]
[00:45:52.889] [0.25 0.25 0.25 0.25]
[00:46:54.019] [0.25 0.25 0.25 0.25]
[00:47:55.146] [0.25 0.25 0.25 0.25]
[00:48:56.235] [0.25 0.25 0.25 0.25]
[00:49:57.352] [0.25 0.25 0.25 0.25]
[00:51:25.065] [0.25 0.25 0.25 0.25]
[00:52:26.219] [0.25 0.25 0.25 0.25]
[00:53:27.366] [0.25 0.25 0.25 0.25]
[00:54:28.474] [0.25 0.25 0.25 0.25]
[00:55:29.567] [0.25 0.25 0.25 0.25]
[00:56:57.216] [0.25 0.25 0.25 0.25]
[00:57:58.306] [0.25 0.25 0.25 0.25]
[00:58:59.405] [0.25 0.25 0.25 0.25]
[01:00:00.473] [0.25 0.25 0.25 0.25]
[01:01:01.573] [0.25 0.25 0.25 0.25]
[01:02:29.262] [0.25 0.25 0.25 0.25]
[01:03:30.382] [0.25 0.25 0.25 0.25]
[01:04:31.475] [0.25 0.25 0.25 0.25]
[01:05:32.596] [0.25 0.25 0.25 0.25]
[01:06:33.696] [0.25 0.25 0.25 0.25]
[01:08:01.390] [0.25 0.25 0.25 0.25]
[01:09:02.515] [0.25 0.25 0.25 0.25]
[01:10:03.609] [0.25 0.25 0.25 0.25]
[01:11:04.652] [0.25 0.25 0.25 0.25]
[01:12:05.698] [0.25 0.25 0.25 0.25]
[01:13:33.381] [0.25 0.25 0.25 0.25]
[01:14:34.487] [0.25 0.25 0.25 0.25]
[01:15:35.579] [0.25 0.25 0.25 0.25]
[01:16:36.662] [0.25 0.25 0.25 0.25]
[01:17:37.789] [0.25 0.25 0.25 0.25]
[01:19:05.468] [0.25 0.25 0.25 0.25]
[01:20:06.526] [0.25 0.25 0.25 0.25]
[01:21:07.609] [0.25 0.25 0.25 0.25]
[01:22:08.696] [0.25 0.25 0.25 0.25]
[01:23:09.836] [0.25 0.25 0.25 0.25]
[01:24:37.448] [0.25 0.25 0.25 0.25]
[01:25:38.526] [0.25 0.25 0.25 0.25]
[01:26:39.616] [0.25 0.25 0.25 0.25]
[01:27:40.665] [0.25 0.25 0.25 0.25]
[01:28:41.768] [0.25 0.25 0.25 0.25]
[01:30:09.403] [0.25 0.25 0.25 0.25]
[01:31:10.460] [0.25 0.25 0.25 0.25]
[01:32:11.507] [0.25 0.25 0.25 0.25]
[01:33:12.551] [0.25 0.25 0.25 0.25]
[01:34:13.600] [0.25 0.25 0.25 0.25]
[01:35:41.258] [0.25 0.25 0.25 0.25]
[01:36:42.295] [0.25 0.25 0.25 0.25]
[01:37:43.402] [0.25 0.25 0.25 0.25]
[01:38:44.480] [0.25 0.25 0.25 0.25]
[01:39:45.528] [0.25 0.25 0.25 0.25]
[01:41:13.129] [0.25 0.25 0.25 0.25]
[01:42:14.197] [0.25 0.25 0.25 0.25]
[01:43:15.250] [0.25 0.25 0.25 0.25]
[01:44:16.329] [0.25 0.25 0.25 0.25]
[01:45:17.419] [0.25 0.25 0.25 0.25]
[01:46:45.043] [0.25 0.25 0.25 0.25]
[01:47:46.162] [0.25 0.25 0.25 0.25]
[01:48:47.218] [0.25 0.25 0.25 0.25]
[01:49:48.266] [0.25 0.25 0.25 0.25]
[01:50:49.356] [0.25 0.25 0.25 0.25]
[01:52:16.962] [0.25 0.25 0.25 0.25]
[01:53:18.023] [0.25 0.25 0.25 0.25]
[01:54:19.066] [0.25 0.25 0.25 0.25]
[01:55:20.097] [0.25 0.25 0.25 0.25]
[01:56:21.117] [0.25 0.25 0.25 0.25]
[01:57:48.715] [0.25 0.25 0.25 0.25]
[01:58:49.711] [0.25 0.25 0.25 0.25]
[01:59:50.710] [0.25 0.25 0.25 0.25]
[02:00:51.718] [0.25 0.25 0.25 0.25]
[02:01:52.776] [0.25 0.25 0.25 0.25]
[02:03:20.314] [0.25 0.25 0.25 0.25]
[02:04:21.372] [0.25 0.25 0.25 0.25]
[02:05:22.406] [0.25 0.25 0.25 0.25]
[02:06:23.416] [0.25 0.25 0.25 0.25]
[02:07:24.460] [0.25 0.25 0.25 0.25]
[02:08:52.001] [0.25 0.25 0.25 0.25]
[02:09:53.031] [0.25 0.25 0.25 0.25]
[02:10:54.048] [0.25 0.25 0.25 0.25]
[02:11:55.104] [0.25 0.25 0.25 0.25]
[02:12:56.093] [0.25 0.25 0.25 0.25]
[02:14:23.639] [0.25 0.25 0.25 0.25]
[02:15:24.669] [0.25 0.25 0.25 0.25]
[02:16:25.700] [0.25 0.25 0.25 0.25]
[02:17:26.736] [0.25 0.25 0.25 0.25]
[02:18:27.727] [0.25 0.25 0.25 0.25]
[02:19:55.273] [0.25 0.25 0.25 0.25]
[02:20:56.275] [0.25 0.25 0.25 0.25]
[02:21:57.296] [0.25 0.25 0.25 0.25]
[02:22:58.309] [0.25 0.25 0.25 0.25]
[02:23:59.310] [0.25 0.25 0.25 0.25]
[02:27:10.084] 
AL round 5
[02:27:10.118] Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)
[02:27:10.301] [timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[02:28:36.107] [0.25 0.25 0.25 0.25]
[02:29:52.505] [0.25 0.25 0.25 0.25]
[02:31:08.863] [0.25 0.25 0.25 0.25]
[02:32:25.097] [0.25 0.25 0.25 0.25]
[02:33:41.286] [0.25 0.25 0.25 0.25]
[02:35:23.945] [0.25 0.25 0.25 0.25]
[02:36:40.073] [0.25 0.25 0.25 0.25]
[02:37:56.205] [0.25 0.25 0.25 0.25]
[02:39:12.297] [0.25 0.25 0.25 0.25]
[02:40:28.397] [0.25 0.25 0.25 0.25]
[02:42:11.024] [0.25 0.25 0.25 0.25]
[02:43:27.135] [0.25 0.25 0.25 0.25]
[02:44:43.255] [0.25 0.25 0.25 0.25]
[02:45:59.342] [0.25 0.25 0.25 0.25]
[02:47:15.424] [0.25 0.25 0.25 0.25]
[02:48:58.044] [0.25 0.25 0.25 0.25]
[02:50:14.165] [0.25 0.25 0.25 0.25]
[02:51:30.278] [0.25 0.25 0.25 0.25]
[02:52:46.382] [0.25 0.25 0.25 0.25]
[02:54:02.472] [0.25 0.25 0.25 0.25]
[02:55:45.068] [0.25 0.25 0.25 0.25]
[02:57:01.170] [0.25 0.25 0.25 0.25]
[02:58:17.290] [0.25 0.25 0.25 0.25]
[02:59:33.371] [0.25 0.25 0.25 0.25]
[03:00:49.456] [0.25 0.25 0.25 0.25]
[03:02:32.113] [0.25 0.25 0.25 0.25]
[03:03:48.211] [0.25 0.25 0.25 0.25]
[03:05:04.296] [0.25 0.25 0.25 0.25]
[03:06:20.431] [0.25 0.25 0.25 0.25]
[03:07:36.547] [0.25 0.25 0.25 0.25]
[03:09:19.172] [0.25 0.25 0.25 0.25]
[03:10:35.258] [0.25 0.25 0.25 0.25]
[03:11:51.371] [0.25 0.25 0.25 0.25]
[03:13:07.492] [0.25 0.25 0.25 0.25]
[03:14:23.602] [0.25 0.25 0.25 0.25]
[03:16:06.233] [0.25 0.25 0.25 0.25]
[03:17:22.356] [0.25 0.25 0.25 0.25]
[03:18:38.499] [0.25 0.25 0.25 0.25]
[03:19:54.555] [0.25 0.25 0.25 0.25]
[03:21:10.720] [0.25 0.25 0.25 0.25]
[03:22:53.321] [0.25 0.25 0.25 0.25]
[03:24:09.437] [0.25 0.25 0.25 0.25]
[03:25:25.482] [0.25 0.25 0.25 0.25]
[03:26:41.580] [0.25 0.25 0.25 0.25]
[03:27:57.706] [0.25 0.25 0.25 0.25]
[03:29:40.328] [0.25 0.25 0.25 0.25]
[03:30:56.393] [0.25 0.25 0.25 0.25]
[03:32:12.463] [0.25 0.25 0.25 0.25]
[03:33:28.525] [0.25 0.25 0.25 0.25]
[03:34:44.597] [0.25 0.25 0.25 0.25]
